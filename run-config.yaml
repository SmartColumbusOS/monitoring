externalDns:
  args:
    source: ingress
    provider: aws
    policy: upsert-only
    aws-zone-type: public
    registry: txt
    txt-owner-id: scos
    # domain-filter: ${DNS_ZONE}

grafana:
  service:
    type: NodePort
  ingress:
    enabled: true
    annotations:
      alb.ingress.kubernetes.io/healthcheck-path: /api/health
  persistentVolume:
    enabled: true
    accessModes:
      - ReadWriteOnce
    size: 5Gi
  datasources: 
    datasources.yaml:
      apiVersion: 1
      datasources:
      - name: Prometheus
        type: prometheus
        url: http://prometheus-server.prometheus.svc.cluster.local
        access: proxy
        isDefault: true
  dashboards:
    default:
      kube-official-dash:
        gnetId: 2
        revision: 2
        datasource: Prometheus
      kube-nodes:
        gnetId: 7692
        revision: 1
        datasource: Prometheus
      kube-namespace:
        gnetId: 6876
        revision: 2
        datasource: Prometheus
      kube-cluster:
        gnetId: 6873
        revision: 2
        datasource: Prometheus
      kube-pods:
        gnetId: 6879
        revision: 1
        datasource: Prometheus
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
      - name: 'default'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        editable: true
        options:
          path: /var/lib/grafana/dashboards/default

alertmanager:
  service:
    type: NodePort
  ingress:
    enabled: true
    annotations:
      alb.ingress.kubernetes.io/healthcheck-path: /-/healthy

server:
  service:
    type: NodePort
  ingress:
    enabled: true
    annotations:
      alb.ingress.kubernetes.io/healthcheck-path: /-/healthy

serverFiles:
  rules:
    groups:
      - name: k8s
        rules:
        - record: node:capacity_memory_bytes:sum
          expr: sum(kube_node_status_capacity_memory_bytes) by (node)
        - record: node:guarantees_memory_bytes:sum
          expr: sum(kube_pod_container_resource_requests_memory_bytes) by (node)
        - record: node:limits_memory_bytes:sum
          expr: sum(kube_pod_container_resource_limits_memory_bytes) by (node)
        - record: node:capacity_cpu:sum
          expr: sum(kube_node_status_capacity_cpu_cores) by (node)
        - record: node:guarantees_cpu:sum
          expr: sum(kube_pod_container_resource_requests_cpu_cores) by (node)
        - record: node:limits_cpu:sum
          expr: sum(kube_pod_container_resource_limits_cpu_cores) by (node)
        - record: cluster:capacity_memory_bytes:sum
          expr: sum(kube_node_status_capacity_memory_bytes)
        - record: cluster:guarantees_memory_bytes:sum
          expr: sum(kube_pod_container_resource_requests_memory_bytes)
        - record: cluster:limits_memory_bytes:sum
          expr: sum(kube_pod_container_resource_limits_memory_bytes)
        - record: cluster:capacity_cpu:sum
          expr: sum(kube_node_status_capacity_cpu_cores)
        - record: cluster:guarantees_cpu:sum
          expr: sum(kube_pod_container_resource_requests_cpu_cores)
        - record: cluster:limits_cpu:sum
          expr: sum(kube_pod_container_resource_limits_cpu_cores)
  alerts:
    groups:
      # Blackbox probe
      - name: Sites
        rules:
          - alert: SiteDown
            expr: probe_success == 0
            for: 2m
            labels:
              severity: error
            annotations:
              description: '{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 2 minutes.'
              summary: 'Instance {{ $labels.instance }} down'
      - name: Streaming
        rules:
          - alert: StreamingPodDown
            expr: up{strimzi_io_cluster="streaming-service"} == 0
            for: 2m
            labels:
              severity: error
            annotations:
              description: '{{ $labels.kubernetes_pod_name }} has been down for more than 2 minutes.'
              summary: 'Streaming pod {{ $labels.kubernetes_pod_name }} down'
      - name: K8S_Nodes
        rules:
          - alert: LowMemory
            expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100) < 20
            for: 5m
            labels:
              severity: warning
            annotations:
              description: '{{ $labels.instance }} has {{ $value }} percent memory left.'
              summary: 'Low Memory on Instance {{ $labels.instance }}'
          - alert: LowDisk
            expr: (node_filesystem_avail_bytes{device=~"/dev/.*"} / node_filesystem_size_bytes{device=~"/dev/.*"} * 100) < 20
            for: 5m
            labels:
              severity: warning
            annotations:
              description: '{{ $labels.instance }} has {{ $value }} percent disk left.'
              summary: 'Low Disk on Instance {{ $labels.instance }}'
          - alert: LowClusterCPU
            expr: (cluster:capacity_cpu:sum - cluster:guarantees_cpu:sum) < 1
            labels:
              severity: warning
            annotations:
              description: 'Kubernetes cluster has {{ $value }} cores left. New deployments and cron jobs may fail to launch.'
              summary: 'Kubernetes cluster low on CPU cores'
          - alert: LowClusterMemory
            expr: (cluster:capacity_memory_bytes:sum - cluster:guarantees_memory_bytes:sum) < 1000000000 #1GB
            labels:
              severity: warning
            annotations:
              description: 'Kubernetes cluster has {{ $value | humanize }} memory left. New deployments and cron jobs may fail to launch.'
              summary: 'Kubernetes cluster has less than {{ 1000000000.0 | humanize }} memory available'

global:
  ingress:
    annotations:
      kubernetes.io/ingress.class: alb
      alb.ingress.kubernetes.io/tags: scos.delete.on.teardown=true
      alb.ingress.kubernetes.io/scheme: internal

# helm install --name=prometheus --namespace=prometheus \
#   --set global.ingress.annotations."alb\.ingress\.kubernetes\.io\/subnets"="${SUBNETS//,/\\,}" \
#   --set global.ingress.annotations."alb\.ingress\.kubernetes\.io\/security\-groups"="${SECURITY_GROUPS}" \
#   --set grafana.ingress.hosts[0]="grafana\.${DNS_ZONE}" \
#   --set alertmanager.ingress.hosts[0]="alertmanager\.${DNS_ZONE}" \
#   --set server.ingress.hosts[0]="prometheus\.${DNS_ZONE}" \
#   --values prometheus/run-config.yaml prometheus